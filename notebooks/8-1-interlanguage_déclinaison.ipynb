{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b8672-45a4-4ced-b106-87b337f607fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad666dc8-2251-4d92-996d-9ff6bc30422a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier interlanguage_déclinaison.csv a été créé avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Charger les fichiers\n",
    "with open(\"transcriptions_ordonnées.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    transcriptions_data = json.load(f)\n",
    "\n",
    "df_erreurs = pd.read_csv(\"erreurs_déclinaison_corrigé.csv\", sep=',', encoding='utf-8', header=0)\n",
    "df_erreurs.columns = df_erreurs.columns.str.strip()\n",
    "\n",
    "df_stat = pd.read_csv(\"statistiques_erreurs_par_apprenant.csv\", sep=',', encoding='utf-8', header=0)\n",
    "\n",
    "# Préparer le dictionnaire des transcriptions par apprenant\n",
    "transcriptions_dict = {}\n",
    "for entry in transcriptions_data:\n",
    "    if \"transcription automatique\" not in entry:\n",
    "        continue\n",
    "    num_apprenant = entry.get(\"numéro d'apprenant\", \"\")\n",
    "    pays = entry.get(\"pays\", \"\")\n",
    "    transcription_auto = entry[\"transcription automatique\"]\n",
    "    transcription_man = []\n",
    "    transcription_corr = []\n",
    "    for k, v in entry.items():\n",
    "        if k.startswith(\"transcription manuelle\"):\n",
    "            transcription_man.append(v)\n",
    "        elif k.startswith(\"version correcte en polonais\"):\n",
    "            transcription_corr.append(v)\n",
    "    transcriptions_dict[num_apprenant] = {\n",
    "        \"pays\": pays,\n",
    "        \"trans_auto\": transcription_auto,\n",
    "        \"trans_man\": \" \".join(transcription_man),\n",
    "        \"trans_corr\": \" \".join(transcription_corr)\n",
    "    }\n",
    "\n",
    "# Charger le modèle spaCy pour le polonais\n",
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "\n",
    "# Générer les lignes\n",
    "rows = []\n",
    "for idx, row in df_stat.iterrows():\n",
    "    mot_correct = row[\"Forme correcte\"]\n",
    "    mot_interlangue = row[\"Forme erronée (manuel)\"]\n",
    "\n",
    "    apprenants_list = [a.strip() for a in str(row[\"Apprenants\"]).split(\",\")]\n",
    "\n",
    "    for apprenant in apprenants_list:\n",
    "        if apprenant not in transcriptions_dict:\n",
    "            continue\n",
    "\n",
    "        doc = nlp(mot_correct)\n",
    "        if not any(token.pos_ in [\"NOUN\", \"ADJ\"] for token in doc):\n",
    "            continue\n",
    "\n",
    "        match_incorrecte = df_erreurs[df_erreurs[\"forme incorrecte\"] == mot_interlangue]\n",
    "        if match_incorrecte.empty:\n",
    "            cas = \"\"\n",
    "            correspondance = \"\"\n",
    "        else:\n",
    "            cas = match_incorrecte.iloc[0][\"cas\"]\n",
    "            correspondance = match_incorrecte.iloc[0][\"correspondance\"]\n",
    "\n",
    "        match_correcte = df_erreurs[df_erreurs[\"forme correcte\"] == mot_correct]\n",
    "        if match_correcte.empty:\n",
    "            cas_correct = \"\"\n",
    "        else:\n",
    "            cas_correct = match_correcte.iloc[0][\"cas correct\"]\n",
    "\n",
    "        trans_data = transcriptions_dict[apprenant]\n",
    "        pays = trans_data[\"pays\"]\n",
    "        trans_auto = trans_data[\"trans_auto\"]\n",
    "        trans_man = trans_data[\"trans_man\"]\n",
    "        trans_corr = trans_data[\"trans_corr\"]\n",
    "\n",
    "        first_row = not any(r[\"apprenant\"] == apprenant for r in rows)\n",
    "\n",
    "        rows.append({\n",
    "            \"pays\": pays,\n",
    "            \"apprenant\": apprenant,\n",
    "            \"mot (interlangue)\": mot_interlangue,\n",
    "            \"cas\": cas,\n",
    "            \"mot (correcte en polonais)\": mot_correct,\n",
    "            \"cas correct\": cas_correct,\n",
    "            \"mot (automatique)\": \"\",\n",
    "            \"transcription automatique\": trans_auto if first_row else \"\",\n",
    "            \"transcription manuelle\": trans_man if first_row else \"\",\n",
    "            \"version correcte en polonais\": trans_corr if first_row else \"\",\n",
    "            \"correspondance\": correspondance\n",
    "        })\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame(rows)\n",
    "df_result['apprenant'] = df_result['apprenant'].astype(int)\n",
    "\n",
    "def has_transcriptions(row):\n",
    "    if row['transcription automatique'] and row['transcription manuelle'] and row['version correcte en polonais']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df_result['ordre'] = df_result.apply(has_transcriptions, axis=1)\n",
    "df_result = df_result.sort_values(by=['apprenant', 'ordre'])\n",
    "df_result = df_result.drop(columns=['ordre'])\n",
    "\n",
    "df_result.to_csv(\"interlanguage_déclinaison.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Le fichier interlanguage_déclinaison.csv a été créé avec succès.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925f9c7-5999-486d-b63e-c6b230a96bde",
   "metadata": {},
   "source": [
    "##### Correction du fichier `interlanguage_déclinaison.csv` - ajout des mots dans la colonne `mot (automatique)` -> `interlanguage_déclinaison_corrigé.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14389bfc-c738-4666-8eee-34bfdc614ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cas détectés par spaCy : 59\n",
      "Nombre d'entrées 'à compléter' : 15\n",
      "Le fichier a été mis à jour.\n"
     ]
    }
   ],
   "source": [
    "# Charger le fichier CSV\n",
    "df = pd.read_csv(\"interlanguage_déclinaison_corrigé.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# Supprimer les lignes où \"mot (automatique)\" est vide ou manquant\n",
    "df = df[df[\"mot (automatique)\"].notna() & (df[\"mot (automatique)\"].str.strip() != \"\")]\n",
    "\n",
    "# Créer les dictionnaires pour recherche rapide\n",
    "dict_interlangue = dict(zip(df[\"mot (interlangue)\"], df[\"cas (interlangue)\"]))\n",
    "dict_correct = dict(zip(df[\"mot (correcte en polonais)\"], df[\"cas correct\"]))\n",
    "\n",
    "# Construire la liste des valeurs pour \"cas (mot automatique)\"\n",
    "cas_auto_list = []\n",
    "nb_spacy = 0       # Compteur pour cas détectés via spaCy\n",
    "nb_a_completer = 0 # Compteur pour \"à compléter\"\n",
    "\n",
    "for mot_auto in df[\"mot (automatique)\"].astype(str).str.strip():\n",
    "    if mot_auto == \"-\":\n",
    "        cas_auto_list.append(\"-\")\n",
    "        continue\n",
    "\n",
    "    if mot_auto in dict_interlangue:\n",
    "        cas_auto_list.append(dict_interlangue[mot_auto])\n",
    "    elif mot_auto in dict_correct:\n",
    "        cas_auto_list.append(dict_correct[mot_auto])\n",
    "    else:\n",
    "        # Utiliser spaCy pour deviner le cas grammatical\n",
    "        doc = nlp(mot_auto)\n",
    "        if doc and doc[0].morph.get(\"Case\"):\n",
    "            cas_detecte = doc[0].morph.get(\"Case\")[0]  # Ex: \"Acc\", \"Nom\", \"Gen\"\n",
    "            cas_auto_list.append(f\"{cas_detecte} (spaCy)\")\n",
    "            nb_spacy += 1\n",
    "        else:\n",
    "            cas_auto_list.append(\"à compléter\")\n",
    "            nb_a_completer += 1\n",
    "\n",
    "# Insérer la nouvelle colonne juste après \"mot (automatique)\"\n",
    "insert_pos = df.columns.get_loc(\"mot (automatique)\") + 1\n",
    "df.insert(insert_pos, \"cas (mot automatique)\", cas_auto_list)\n",
    "\n",
    "# Supprimer la colonne \"correspondance\"\n",
    "if \"correspondance\" in df.columns:\n",
    "    df = df.drop(columns=[\"correspondance\"])\n",
    "\n",
    "# Sauvegarder le fichier mis à jour\n",
    "df.to_csv(\"interlanguage_déclinaison_corrigé.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Afficher les statistiques\n",
    "print(f\"Cas détectés par spaCy : {nb_spacy}\")\n",
    "print(f\"Nombre d'entrées 'à compléter' : {nb_a_completer}\")\n",
    "print(\"Le fichier a été mis à jour.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11aa3bc-b421-40cf-8dc2-ca6ed5969f55",
   "metadata": {},
   "source": [
    "##### Correction du fichier `interlanguage_déclinaison_corrigé.csv` - correction des cas dans la colonne `cas (mot automatique)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65d09fb0-78ad-4f70-b0e0-939ea7487a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des lignes où le cas interlangue est correct (c'est-à-dire cas (interlangue) == cas correct)\n",
    "df_decl_err = df[df[\"cas (interlangue)\"] != df[\"cas correct\"]]\n",
    "\n",
    "df_decl_err.to_csv(\"interlanguage_déclinaison_corrigé_final.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7730144-7611-48a9-8b99-788cd5faba53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
