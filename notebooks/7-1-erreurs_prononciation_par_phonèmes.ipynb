{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f43671-d4e7-492c-9d04-a88002744145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221dd65-f0a9-4d01-9941-eb024ddebb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "POLISH_DIGRAPHS = [\"ch\", \"cz\", \"dz\", \"dź\", \"dż\", \"rz\", \"sz\", \"eu\", \"ou\"]\n",
    "ENDING_SUFFIXES = [\"ą\", \"a\", \"u\", \"em\", \"ę\", \"i\", \"y\", \"ej\", \"ich\", \"ego\", \"e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714fc355-a879-4c1e-9522-12ee6015ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier mis à jour : erreurs_prononciation.csv.\n"
     ]
    }
   ],
   "source": [
    "# Fonctions\n",
    "def split_phonetic_units(word):\n",
    "    i, units = 0, []\n",
    "    while i < len(word):\n",
    "        matched = False\n",
    "        for digraph in sorted(POLISH_DIGRAPHS, key=len, reverse=True):\n",
    "            if word[i:i+len(digraph)] == digraph:\n",
    "                units.append(digraph)\n",
    "                i += len(digraph)\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            units.append(word[i])\n",
    "            i += 1\n",
    "    return units\n",
    "\n",
    "def strip_ending(correct, incorrect):\n",
    "    if correct.endswith(\"ą\") and incorrect.endswith((\"on\", \"om\", \"o\")):\n",
    "        return correct\n",
    "    if correct.endswith(\"ę\") and incorrect.endswith(\"en\"):\n",
    "        return correct\n",
    "    if correct.endswith(\"o\") and incorrect.endswith(\"eu\"):\n",
    "        return correct\n",
    "    if correct.endswith(\"eu\") and incorrect.endswith(\"o\"):\n",
    "        return correct\n",
    "    for suffix in sorted(ENDING_SUFFIXES, key=len, reverse=True):\n",
    "        if correct.endswith(suffix):\n",
    "            return correct[:-len(suffix)]\n",
    "    return correct\n",
    "\n",
    "def find_differences(correct, incorrect):\n",
    "    correct_base = strip_ending(correct, incorrect)\n",
    "    incorrect_base = strip_ending(incorrect, correct)\n",
    "    correct_units = split_phonetic_units(correct_base)\n",
    "    incorrect_units = split_phonetic_units(incorrect_base)\n",
    "    matcher = SequenceMatcher(None, correct_units, incorrect_units)\n",
    "    differences = []\n",
    "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "        if tag != 'equal':\n",
    "            differences.append({\n",
    "                \"correct\": \"\".join(correct_units[i1:i2]) if i1 != i2 else \"-\",\n",
    "                \"incorrect\": \"\".join(incorrect_units[j1:j2]) if j1 != j2 else \"-\"\n",
    "            })\n",
    "    return differences\n",
    "\n",
    "# Lecture CSV de base\n",
    "df = pd.read_csv(\"statistiques_erreurs_par_apprenant.csv\")\n",
    "\n",
    "# Création d'une version \"aplatie\"\n",
    "rows = []\n",
    "for _, row in df.iterrows():\n",
    "    correct_word = str(row[\"Forme correcte\"])\n",
    "    incorrect_word = str(row[\"Forme erronée (manuel)\"])\n",
    "    differences = find_differences(correct_word, incorrect_word)\n",
    "\n",
    "    if not differences:\n",
    "        continue\n",
    "\n",
    "    for diff in differences:\n",
    "        new_row = {\n",
    "            \"Forme correcte\": correct_word,\n",
    "            \"Forme erronée (manuel)\": incorrect_word,\n",
    "            \"Correcte\": diff[\"correct\"],\n",
    "            \"Erroné\": diff[\"incorrect\"]\n",
    "        }\n",
    "        for col in [\"FR\", \"IT\", \"NL\", \"UK\", \"GE\", \"Nombre d'apprenants\"]:\n",
    "            new_row[col] = row.get(col, 0)\n",
    "        \n",
    "        # Dodanie kolumny Apprenants z listą uczniów\n",
    "        new_row[\"Apprenants\"] = row.get(\"Apprenants\", \"\")\n",
    "\n",
    "        rows.append(new_row)\n",
    "\n",
    "flat_df = pd.DataFrame(rows)\n",
    "\n",
    "# Ajout d'une colonne clé de groupe basée sur Correcte et Erroné\n",
    "flat_df[\"pair_key\"] = flat_df[\"Correcte\"] + \"|\" + flat_df[\"Erroné\"]\n",
    "\n",
    "# Calcule la priorité de tri pour chaque groupe de paire\n",
    "pair_priority = flat_df.groupby(\"pair_key\")[\"Nombre d'apprenants\"].transform(\"max\")\n",
    "\n",
    "# Trie d'abord par priorité du groupe (desc), puis par Nombre d'apprenants (desc)\n",
    "flat_df_sorted = flat_df.assign(group_priority=pair_priority).sort_values(\n",
    "    by=[\"group_priority\", \"Correcte\", \"Erroné\", \"Nombre d'apprenants\"],\n",
    "    ascending=[False, True, True, False]\n",
    ").drop(columns=[\"pair_key\", \"group_priority\"])\n",
    "\n",
    "# Sauvegarde\n",
    "flat_df_sorted.to_csv(\"erreurs_prononciation.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Fichier mis à jour : erreurs_prononciation.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05c0e6e-8db7-47c9-bf47-7e4e990d9fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier JSON mis à jour : alignement_mots_manuel_correct_prononciation.json\n"
     ]
    }
   ],
   "source": [
    "# Création du dictionnaire (correct, manuel) → liste des lettres\n",
    "diff_dict = defaultdict(list)\n",
    "for _, row in flat_df.iterrows():\n",
    "    key = (row[\"Forme correcte\"], row[\"Forme erronée (manuel)\"])\n",
    "    diff_dict[key].append((row[\"Correcte\"], row[\"Erroné\"]))\n",
    "\n",
    "# Mise à jour du JSON\n",
    "with open(\"alignement_mots_manuel_correct.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for record in data:\n",
    "    for segment in record[\"segments\"]:\n",
    "        for mot in segment[\"segments\"]:\n",
    "            key = (mot.get(\"correct\", \"\"), mot.get(\"manuel\", \"\"))\n",
    "            lettres = diff_dict.get(key, [])\n",
    "            if lettres:\n",
    "                for idx, (c, m) in enumerate(lettres, start=1):\n",
    "                    mot[f\"lettre_correct_{idx}\"] = c\n",
    "                    mot[f\"lettre_manuel_{idx}\"] = m\n",
    "            else:\n",
    "                mot[\"lettre_correct_1\"] = \"\"\n",
    "                mot[\"lettre_manuel_1\"] = \"\"\n",
    "\n",
    "with open(\"alignement_mots_manuel_correct_prononciation.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "print(\"Fichier JSON mis à jour : alignement_mots_manuel_correct_prononciation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3ff44a-493b-4884-86b9-c77eb0cd4f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier erreurs_prononciation_groupées_par_phonèmes.csv.\n"
     ]
    }
   ],
   "source": [
    "# Dictionnaire des ensembles d'apprenants par (Correcte, Erroné)\n",
    "apprenants_dict = defaultdict(set)\n",
    "\n",
    "for _, row in flat_df.iterrows():\n",
    "    key = (row[\"Correcte\"], row[\"Erroné\"])\n",
    "    apprenants_str = row.get(\"Apprenants\", \"\")\n",
    "    if pd.notna(apprenants_str) and apprenants_str.strip() != \"\":\n",
    "        apprenants_set = set(x.strip() for x in apprenants_str.split(\",\"))\n",
    "        apprenants_dict[key].update(apprenants_set)\n",
    "\n",
    "# Map du premier chiffre vers le pays\n",
    "country_map = {\n",
    "    \"1\": \"FR\",\n",
    "    \"5\": \"IT\",\n",
    "    \"2\": \"NL\",\n",
    "    \"3\": \"UK\",\n",
    "    \"4\": \"GE\"\n",
    "}\n",
    "\n",
    "# Pour chaque paire (Correcte, Erroné), créer un dictionnaire pour compter les apprenants par pays\n",
    "country_counts = defaultdict(lambda: {\"FR\": 0, \"IT\": 0, \"NL\": 0, \"UK\": 0, \"GE\": 0})\n",
    "\n",
    "for key, apprenants in apprenants_dict.items():\n",
    "    # Comptage unique par pays\n",
    "    counted = {\"FR\": set(), \"IT\": set(), \"NL\": set(), \"UK\": set(), \"GE\": set()}\n",
    "    for apprenant in apprenants:\n",
    "        if apprenant and apprenant[0] in country_map:\n",
    "            pays = country_map[apprenant[0]]\n",
    "            counted[pays].add(apprenant)\n",
    "    for pays in counted:\n",
    "        country_counts[key][pays] = len(counted[pays])\n",
    "\n",
    "# Création du résumé avec les totaux mis à jour\n",
    "summary_rows = []\n",
    "for key in apprenants_dict.keys():\n",
    "    total_apprenants = len(apprenants_dict[key])\n",
    "    row = {\n",
    "        \"Correcte\": key[0],\n",
    "        \"Erroné\": key[1],\n",
    "        \"FR\": country_counts[key][\"FR\"],\n",
    "        \"IT\": country_counts[key][\"IT\"],\n",
    "        \"NL\": country_counts[key][\"NL\"],\n",
    "        \"UK\": country_counts[key][\"UK\"],\n",
    "        \"GE\": country_counts[key][\"GE\"],\n",
    "        \"Nombre total d'apprenants\": total_apprenants\n",
    "    }\n",
    "    summary_rows.append(row)\n",
    "\n",
    "summary = pd.DataFrame(summary_rows)\n",
    "\n",
    "# Ajout de la colonne \"Examples de mots\"\n",
    "mot_dict = defaultdict(set)\n",
    "for _, row in flat_df.iterrows():\n",
    "    key = (row[\"Correcte\"], row[\"Erroné\"])\n",
    "    mot_dict[key].add(row[\"Forme correcte\"])\n",
    "\n",
    "summary[\"Examples de mots\"] = summary.apply(\n",
    "    lambda row: \", \".join(sorted(mot_dict[(row[\"Correcte\"], row[\"Erroné\"])])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Tri par nombre d'apprenants décroissant\n",
    "summary = summary.sort_values(by=\"Nombre total d'apprenants\", ascending=False)\n",
    "\n",
    "summary.to_csv(\"erreurs_prononciation_groupées_par_phonèmes.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Fichier erreurs_prononciation_groupées_par_phonèmes.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4518058-3346-4679-9209-b616cf1a55cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé : erreurs_prononciation_groupées_par_phonèmes_API.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import epitran\n",
    "\n",
    "# Initialisation de l'outil de translittération Epitran pour le polonais\n",
    "epi = epitran.Epitran('pol-Latn')\n",
    "\n",
    "# Lecture du fichier original avec les erreurs de prononciation\n",
    "df = pd.read_csv(\"erreurs_prononciation_groupées_par_phonèmes.csv\")\n",
    "\n",
    "# Fonction de translittération simple pour une cellule texte\n",
    "def convert_to_ipa(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return epi.transliterate(text)\n",
    "\n",
    "# Fonction de translittération pour la colonne contenant plusieurs mots séparés par des virgules\n",
    "def convert_examples_to_ipa(examples):\n",
    "    if pd.isna(examples) or not isinstance(examples, str):\n",
    "        return \"\"\n",
    "    words = [word.strip() for word in examples.split(\",\")]\n",
    "    ipa_words = [epi.transliterate(word) for word in words]\n",
    "    return \", \".join(ipa_words)\n",
    "\n",
    "# Remplacement des colonnes par leurs équivalents phonétiques\n",
    "df[\"Correcte\"] = df[\"Correcte\"].apply(convert_to_ipa)\n",
    "df[\"Erroné\"] = df[\"Erroné\"].apply(convert_to_ipa)\n",
    "df[\"Examples de mots\"] = df[\"Examples de mots\"].apply(convert_examples_to_ipa)\n",
    "\n",
    "# Sauvegarde dans un nouveau fichier CSV\n",
    "df.to_csv(\"erreurs_prononciation_groupées_par_phonèmes_API.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Fichier sauvegardé : erreurs_prononciation_groupées_par_phonèmes_API.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9d642-df41-41bd-bbfc-82c692ab429a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
